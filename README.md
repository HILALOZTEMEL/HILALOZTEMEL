



### Hi there ðŸ‘‹ this is Hilal Ã–ztemel

- ðŸ”­ Iâ€™m currently working on Deep Learning and Computer Vision

### Socials

[![alt text][1.1]][1]



[1.1]: https://img.icons8.com/nolan/64/linkedin-circled.png (twitter icon with padding)



[1]: https://www.linkedin.com/in/hilal-%C3%B6ztemel-290a09209/?originalSubdomain=tr


### Face Mask Detection with CNN : https://github.com/HILALOZTEMEL/Face-Mask-Detection

https://github.com/user-attachments/assets/671a7de0-475a-4ff0-a179-f831a8a60de1


### Object Detection with YOLO : https://github.com/HILALOZTEMEL/UNDERWATER-OBJECT-DETECTION-WITH-YOLOV7-

https://github.com/user-attachments/assets/fa75cdc3-ab5d-4464-bd0d-2df0548e0ec0


https://github.com/user-attachments/assets/68e9cc07-6e0c-44c6-9667-d3614f961bf0

### Stock Price Prediction Project : https://github.com/HILALOZTEMEL/Stock_Price_Prediction/blob/main/Stock_Price_Prediction.ipynb
In this project, I aimed to predict stock prices using various machine learning algorithms, including Random Forest Regressor, Gradient Boosting Regressor, Support Vector Regressor (SVR), and XGBoost. The dataset was divided into training and testing sets, with features such as date, closing price, and trading volume used to build the models. The performance of each model was evaluated using key metrics like Mean Squared Error (MSE), Mean Absolute Error (MAE), and R-squared (RÂ²) to assess prediction accuracy.

The Random Forest Regressor demonstrated strong performance, achieving an MSE of 0.0014889, an MAE of 0.01759, and an R-squared of 0.9996, making it one of the top performers. Similarly, the Gradient Boosting Regressor performed well, with an MSE of 0.0028410, an MAE of 0.02487, and an R-squared of 0.9993. On the other hand, the SVR model had a significantly higher error, with an MSE of 2.4648, an MAE of 0.7975, and a lower R-squared value of 0.3942, indicating weaker predictive capability. Finally, the XGBoost model also delivered excellent results, with an MSE of 0.0048822, an MAE of 0.02775, and an R-squared of 0.9988.

By comparing the models, the Random Forest Regressor and XGBoost emerged as the best-performing algorithms, highlighting my ability to implement effective time-series forecasting techniques for financial data using various machine learning models.


### Car Price Prediction Project : https://github.com/HILALOZTEMEL/Car_price_prediction/blob/main/Car_price_prediction.ipynb
In this project, I developed a machine learning model to predict car prices using various algorithms such as Random Forest Regressor, Gradient Boosting Regressor, Support Vector Regressor (SVR), and XGBoost. The dataset was split into training and testing sets to evaluate the performance of each model. Key metrics, including Mean Squared Error (MSE), Mean Absolute Error (MAE), and R-squared (RÂ²), were used to assess prediction accuracy. By comparing different models, I was able to identify the most effective one for accurate car price predictions, showcasing my skills in feature engineering and regression analysis.

The Random Forest Regressor performed strongly, with an MSE of 4,150,096.75, an MAE of 1,425.61, and an R-squared of 0.9401, making it one of the top performers. The Gradient Boosting Regressor also showed solid results, achieving an MSE of 5,504,701.80, an MAE of 1,647.99, and an R-squared of 0.9205. However, the SVR model underperformed, with a significantly higher MSE of 74,003,552.59, an MAE of 5,471.24, and a negative R-squared of -0.0681, indicating poor prediction accuracy. Finally, the XGBoost model achieved relatively good results, with an MSE of 6,106,854.99, an MAE of 1,681.27, and an R-squared of 0.9119.

Through these comparisons, the Random Forest Regressor was selected as the most effective model for predicting car prices, demonstrating my ability to apply machine learning algorithms effectively for regression tasks and predictive modeling.

### Flight Ticket Price Prediction Project : https://github.com/HILALOZTEMEL/Flight_ticket_price_prediction/tree/main
This project focuses on predicting flight ticket prices using machine learning models. It aims to help users estimate ticket prices for specific flight routes and dates. I used several machine learning algorithms to experiment with model accuracy, including Random Forest, Gradient Boosting, Support Vector Regressor (SVR), and XGBoost.

After training the models on the dataset, the XGBoost model demonstrated the best performance, with a Mean Squared Error (MSE) of 3,098,512.36, a Mean Absolute Error (MAE) of 1,145.32, and an R-squared value of 0.8481. These results indicate that the XGBoost model is the most accurate in predicting flight ticket prices, capturing around 84.81% of the variance in the dataset.

This project highlights my expertise in data preprocessing, model training, and performance evaluation, and demonstrates my ability to apply machine learning techniques to real-world problems.















